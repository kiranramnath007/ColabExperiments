{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "HICO DET Faster RCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kiranramnath007/ColabExperiments/blob/master/HICO_DET_Faster_RCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lusDX3lCvyiu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_CLASSES = 49"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xCQOoKtZNHyW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0408b06a-dfc8-4047-96ff-aba699e9cd63"
      },
      "source": [
        "import torch, torchvision\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torchvision import transforms\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from torch import optim\n",
        "from collections import OrderedDict\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import time\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn.metrics import average_precision_score\n",
        "# For training\n",
        "images = torch.rand(10, 3, 287, 640)\n",
        "\n",
        "#7 box per image\n",
        "boxes1 = torch.ones(5, 7, 4) #2 images, 7 bbox, 4 co-ords\n",
        "labels1 = torch.randint(0,2, (5,NUM_CLASSES)).float()\n",
        "\n",
        "#11 boxes per image\n",
        "boxes2 = torch.zeros(5,11,4)\n",
        "labels2 = torch.randint(0,2,(5,NUM_CLASSES)).float()\n",
        "\n",
        "boxes = torch.unbind(boxes1) + torch.unbind(boxes2)\n",
        "#boxes = torch.zeros(5,11,4)\n",
        "labels = torch.cat((labels1, labels2), dim = 0)\n",
        "lengths = [7,7,7,7,7,11,11,11,11,11,11]\n",
        "#images = list(image for image in images)\n",
        "targets = []\n",
        "for i in range(len(images)):\n",
        "    d = {}\n",
        "    d['boxes'] = boxes[i]\n",
        "    #d['labels'] = labels[i]\n",
        "    targets.append(d)\n",
        "#output = model(images, targets)\n",
        "\n",
        "#Transform\n",
        "transform = transforms.Compose([transforms.Resize(256),\n",
        "                                transforms.CenterCrop(224),\n",
        "                                transforms.ToTensor()])\n",
        "\n",
        "#Pack bounding box tensor into one \n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "packed_boxes = pad_sequence(boxes, batch_first=True)\n",
        "packed_boxes.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 11, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nebt32yPCTWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MzEfCAs6NHyc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a63b06fb-167f-4379-d27a-96f080fb475b"
      },
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/drive/My Drive/Research/Code/\")\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "from fast_rcnn import *"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BEdR2zBLWLTy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5600a95d-4a63-49cd-d8e7-f088da5454d2"
      },
      "source": [
        "# !cp /content/drive/My\\ Drive/Research/Data/HICO_DET/subset.zip /content/subset.zip\n",
        "# #!unzip /content/drive/My\\ Drive/Research/Data/HICO_DET/subset.zip -d /content/drive/My\\ Drive/Research/Data/images2/\n",
        "# !unzip /content/subset.zip -d /content/images/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/subset.zip\n",
            "replace /content/images/subset/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kT-ypOb_H-1v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b01c1af7-9faa-448b-ecac-e5d4240066f0"
      },
      "source": [
        "!cp -r /content/drive/My\\ Drive/Research/Data/Tensors/ /content/\n",
        "!mv /content/Tensors/ /content/Images/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mv: cannot move '/content/Tensors/' to '/content/Images/Tensors': Directory not empty\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UmyX3_joNHyf",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "gpu_flag = False\n",
        "if torch.cuda.is_available():\n",
        "    gpu_flag = True\n",
        "model = fastrcnn_resnet50_fpn(pretrained_backbone=True, num_classes = NUM_CLASSES, trainable=False,gpu = gpu_flag)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-0mbvhPhNHyk",
        "outputId": "c2165a78-8109-4a97-b2a3-c656796b1bb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "time_start = time.time()\n",
        "model.train()\n",
        "pos_weight = 10*torch.ones(NUM_CLASSES)\n",
        "if gpu_flag:\n",
        "    images = images.cuda()\n",
        "    labels = labels.cuda()\n",
        "    pos_weight = pos_weight.cuda()\n",
        "    for t in targets:\n",
        "        t[\"boxes\"] = t[\"boxes\"].cuda()\n",
        "predictions2 = model(images, targets, labels, pos_weight = pos_weight, batch_size = 10, gpu = gpu_flag)\n",
        "print(time.time()-time_start)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.57574462890625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xWVdjxXoNHyu",
        "colab": {}
      },
      "source": [
        "# For inference\n",
        "model.eval()\n",
        "pos_weight = 10*torch.ones(NUM_CLASSES)\n",
        "predictions = model(images, targets, labels, pos_weight = pos_weight, batch_size = 10, gpu = gpu_flag)\n",
        "predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A_8-7ArTNHyy",
        "colab": {}
      },
      "source": [
        "# Set the maximum sequence length. \n",
        "\n",
        "class BucketDataset:\n",
        "\n",
        "    def __init__(self, inputs, targets, labels, lengths, batch_size):\n",
        "        self.inputs = inputs      # shape = (N, max_seq_len)\n",
        "        self.targets = targets    # shape = (N, ) or None (e.g., for autoencoder I can simply use inputs)\n",
        "        self.lengths = lengths    # shape = (N, )\n",
        "        self.labels = labels\n",
        "        self.lengths_tensor = torch.tensor(self.lengths)\n",
        "        self.batch_size = batch_size\n",
        "        self.current = -1\n",
        "        self._generate_batch_map()\n",
        "\n",
        "    def _generate_batch_map(self, equal_length=False):\n",
        "        batch_map = OrderedDict()\n",
        "        # Organize lengths, e.g., batch_map[10] = [30, 124, 203, ...] <= indices of sequences of length 10\n",
        "        for idx, length in enumerate(self.lengths):\n",
        "            if length not in batch_map:\n",
        "                batch_map[length] = [idx]\n",
        "            else:\n",
        "                batch_map[length].append(idx)\n",
        "        # Use batch_map to split indices into batches of equal size\n",
        "        # e.g., for batch_size=3, batch_list = [[23,45,47], [49,50,62], [63,65,66], ...]\n",
        "        self.batch_list = []\n",
        "        for length, indices in batch_map.items():\n",
        "            for group in [indices[i:(i+self.batch_size)] for i in range(0, len(indices), self.batch_size)]:\n",
        "                self.batch_list.append((length,group))\n",
        "        self.batch_list = sorted(self.batch_list)\n",
        "        self.batch_list = [b[1] for b in self.batch_list]\n",
        "\n",
        "    def batch_count(self):\n",
        "        return len(self.batch_list)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.lengths)\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        self.current = self.current + 1\n",
        "        if self.current > len(self.batch_list)-1:\n",
        "            self.current = -1\n",
        "            raise StopIteration\n",
        "        else:\n",
        "            t = set(self.batch_list[self.current])\n",
        "            indices = [True if index in t else False for index in range(len(self.inputs))]\n",
        "            l = self.lengths_tensor[indices]\n",
        "\n",
        "            return self.inputs[indices], \\\n",
        "                   [{\"boxes\":t} for t in self.targets[indices][:,:l[0],:]], \\\n",
        "                   self.labels[indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RgLL0-4xNH0a",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "def step(bucket, test_bucket, optimizer, model, pos_weight, epoch, partition,scheduler, gpu = False):\n",
        "    running_loss = 0.0\n",
        "    num_buckets = len(bucket.batch_list)\n",
        "    checkpoint_every = max(num_buckets // 2, 1)\n",
        "    time_start = time.time()\n",
        "    for index, mb in enumerate(bucket):\n",
        "        time_start_getting_data = time.time()\n",
        "        inputs, targets, labels = mb\n",
        "        if gpu:\n",
        "            inputs = inputs.cuda()\n",
        "            for t in targets:\n",
        "                t[\"boxes\"] = t[\"boxes\"].cuda()\n",
        "            labels = labels.cuda()\n",
        "            pos_weight = pos_weight.cuda()\n",
        "        batch_size = len(targets)\n",
        "        print(inputs.shape, labels.shape, targets[0][\"boxes\"].shape)\n",
        "        # print(\"Time to get data from minibatch\", time.time() - time_start_getting_data)\n",
        "        \n",
        "        time_start_forward = time.time()\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        model.train()\n",
        "        # forward + backward + optimize\n",
        "        #print(\"Labels \",labels.shape,\" image \",inputs.shape, \" batch_size \", batch_size)\n",
        "        losses = model(inputs, targets, labels, batch_size, pos_weight, gpu)\n",
        "        loss = losses[\"loss_classifier\"]\n",
        "        \n",
        "        # print(\"Time taken for forward pass\", time.time() - time_start_forward)\n",
        "        \n",
        "        time_start_backward_prop = time.time()        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # print(\"time taken for backward propagation\", time.time() - time_start_backward_prop)\n",
        "        print(\"Batch size\", batch_size, \"Loss\", loss.item())\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        if index % checkpoint_every == 0:\n",
        "            checkpoint = {'model': model,\n",
        "                      'state_dict': model.state_dict(),\n",
        "                      'optimizer' : optimizer.state_dict()}\n",
        "\n",
        "            torch.save(checkpoint, 'action_detector_epoch_'+str(epoch)+'_partition_'+str(partition)+'.pth')\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                y_pred_train = model(inputs, targets, labels, batch_size, pos_weight, gpu)\n",
        "                if gpu:\n",
        "                    y_pred_train = y_pred_train.cpu()\n",
        "                    labels = labels.cpu()\n",
        "                train_average_precision = average_precision_score(labels, y_pred_train, average=\"micro\")\n",
        "                print(\"Train average precision is \", train_average_precision)\n",
        "                \n",
        "                test_average_precision = 0\n",
        "                if test_bucket is None:\n",
        "                    continue\n",
        "                for test_mb in test_bucket:\n",
        "                    inputs, targets, labels = test_mb\n",
        "                    batch_size = len(targets)\n",
        "                    if gpu:\n",
        "                        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "                        for t in targets:\n",
        "                            t[\"boxes\"] = t[\"boxes\"].cuda()\n",
        "                            \n",
        "                    y_pred = model(inputs, targets, labels, batch_size, pos_weight, gpu)            \n",
        "                    if gpu:\n",
        "                        y_pred = y_pred.cpu()\n",
        "                        labels = labels.cpu()\n",
        "                    test_average_precision += average_precision_score(labels, y_pred, average=\"micro\")\n",
        "                print(\"Test average precision\", test_average_precision / len(test_bucket))\n",
        "        scheduler.step()        \n",
        "        print(\"Epoch\",epoch,\"Iteration \",index,\"Partition\",partition,\"running_loss\",running_loss)\n",
        "        # n_iter = epoch*2400 + partition*111 + iteration\n",
        "        # writer.add_scalar('Loss/train', np.random.random(), n_iter)\n",
        "        # writer.add_scalar('Loss/test', np.random.random(), n_iter)\n",
        "        # writer.add_scalar('Accuracy/train', np.random.random(), n_iter)\n",
        "        # writer.add_scalar('Accuracy/test', np.random.random(), n_iter)\n",
        "        #print(\"Time taken for one iteration\",time.time() - time_start_getting_data)\n",
        "    return running_loss    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pbc_Z2_jNH0d",
        "colab": {}
      },
      "source": [
        "def train_net(model, test_bucket = None, epochs = 20, batch_size = 10, gpu = False):\n",
        "    \n",
        "    optimizer = optim.SGD(model.parameters(), lr=1e-2, weight_decay=1e-3, momentum=0.9)\n",
        "    #scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 18000, gamma=0.1)\n",
        "    scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=1e-4, max_lr=1e-3, step_size_up = 2400)\n",
        "    pos_weight = 10*torch.ones(NUM_CLASSES) #10 is the weight attached to misclassified positive sample\n",
        "\n",
        "    writer = SummaryWriter() #\n",
        "    for epoch in range(epochs):\n",
        "        print(\"Epoch number \",epoch)\n",
        "        for partition in range(11):\n",
        "            images = torch.load(data_directory + \"train_images_\" + str(partition) + \".pt\")\n",
        "            boxes = torch.load(data_directory + \"train_boxes_\" + str(partition) + \".pt\")\n",
        "            labels = torch.load(data_directory + \"train_labels_\" + str(partition) + \".pt\")\n",
        "            with (open(data_directory + \"train_lengths_\" + str(partition) + \".txt\", \"rb\")) as picklefile:\n",
        "              lengths = pickle.load(picklefile)\n",
        "            buckets = BucketDataset(images, boxes, labels, lengths, batch_size)\n",
        "            step(buckets, test_bucket, optimizer, model,pos_weight,epoch, partition,scheduler,gpu)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Cv_qOUU4NH0h",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "import json\n",
        "anno_directory = \"/content/drive/My Drive/Research/Data/\"\n",
        "data_directory = \"/content/Images/\"\n",
        "with open(anno_directory + 'HICO_DET/subset_anno_list_with_bg_class.json') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# data_directory = \"../../Data/HICO/data_symlinks/\"\n",
        "# with open(data_directory + 'hico_processed/subset_anno_list_with_bg_class.json') as f:\n",
        "#     data = json.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWCBTi3WWg30",
        "colab_type": "code",
        "outputId": "bcaa5ae4-8acf-46e9-e1ba-7a31887a4a8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oARaqC01NH0k"
      },
      "source": [
        "### Extract ground truth bounding boxes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Gbw3r4gfNH0n",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "#This gets one-image one-bbox data\n",
        "\n",
        "def one_box_one_image_data(data):\n",
        "    per_image_data = {}\n",
        "    c = 0\n",
        "\n",
        "    for image_data in data:\n",
        "        global_id = image_data['global_id']\n",
        "        for hoi in image_data['hois']:\n",
        "            bbox = hoi['human_bboxes']\n",
        "            label = hoi['id']\n",
        "            image_path = image_data['image_path_postfix']\n",
        "            image_size = image_data['image_size']\n",
        "            per_image_data[c] = {\"bbox\":bbox, \"label\":int(label), \"path\":image_path,'image_size':image_size}\n",
        "            c += 1\n",
        "\n",
        "    l = []\n",
        "    for key in per_image_data:\n",
        "        l.append(per_image_data[key][\"label\"])\n",
        "\n",
        "    lt = torch.tensor(l)\n",
        "    one_hot = torch.nn.functional.one_hot(lt)\n",
        "\n",
        "    for index,t in enumerate(one_hot):\n",
        "        per_image_data[index][\"label\"] = t\n",
        "    \n",
        "    return per_image_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sQ1uyFGcNH0q",
        "colab": {}
      },
      "source": [
        "#This gets one-image all-box data\n",
        "\n",
        "def one_image_all_box_data(data):\n",
        "    ret = []\n",
        "    \n",
        "    for image_data in data:\n",
        "        global_id = image_data[\"global_id\"]\n",
        "        bboxes = []\n",
        "        labels = []\n",
        "        image_path = image_data['image_path_postfix']\n",
        "        image_size = image_data[\"image_size\"]\n",
        "        \n",
        "        for hoi in image_data[\"hois\"]:\n",
        "            bboxes += hoi[\"human_bboxes\"]\n",
        "            labels += [float(hoi[\"id\"])]*len(hoi[\"human_bboxes\"])\n",
        "                    \n",
        "        ret.append({\"global_id\":global_id, \"boxes\":bboxes, \"labels\":labels,\n",
        "                            \"image_path\":image_path,\"image_size\":image_size})\n",
        "    return ret\n",
        "ret = one_image_all_box_data(data)            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEZLisd_WdZN",
        "colab_type": "code",
        "outputId": "000fc5e5-0788-442c-864f-9668280b27c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(ret)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ipb7xdwlNH0t",
        "colab": {}
      },
      "source": [
        "train_annot = [d for d in ret if d[\"image_path\"].startswith(\"train\")]\n",
        "test_annot = [d for d in ret if d[\"image_path\"].startswith(\"test\")]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m3ckzEdqNH0x",
        "colab": {}
      },
      "source": [
        "def resize_boxes(boxes, original_size, new_size):\n",
        "    # type: (Tensor, List[int], List[int])\n",
        "    ratios = [float(s) / float(s_orig) for s, s_orig in zip(new_size, original_size)]\n",
        "    ratio_height, ratio_width = ratios\n",
        "    xmin, ymin, xmax, ymax = boxes.unbind(1)\n",
        "\n",
        "    xmin = xmin * ratio_width\n",
        "    xmax = xmax * ratio_width\n",
        "    ymin = ymin * ratio_height\n",
        "    ymax = ymax * ratio_height\n",
        "    return torch.stack((xmin, ymin, xmax, ymax), dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d14WYUE0NH00",
        "outputId": "d8545d14-37ff-4a81-ebce-9196ac46145e",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "img_path = \"../../Data/HICO/data_symlinks/hico_clean/images/\"+ret[6953][\"image_path\"]\n",
        "#img = Image.open(img_path) # Load the image\n",
        "img = cv2.imread(img_path) # Read image with cv2\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Convert to RGB\n",
        "coords= ret[6953][\"boxes\"]\n",
        "for c in coords:\n",
        "    cv2.rectangle(img, (int(c[0]), int(c[1])), (int(c[2]), int(c[3])),color=(0, 255, 0), thickness=1) # Draw Rectangle with the coordinates\n",
        "#cv2.putText(img,pred_cls[i], boxes[i][0],  cv2.FONT_HERSHEY_SIMPLEX, text_size, (0,255,0),thickness=text_th) # Write the prediction class\n",
        "plt.figure(figsize=(20,30)) # display the output image\n",
        "plt.imshow(img)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "\n",
        "\n",
        "plt.imshow(img)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-75ca34156650>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#img = Image.open(img_path) # Load the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Read image with cv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Convert to RGB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6953\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"boxes\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_r1ZAuDPNH04",
        "colab": {}
      },
      "source": [
        "# img = cv2.imread(img_path) # Read image with cv2\n",
        "# img = cv2.resize(img, (640, 640), interpolation = cv2.INTER_LINEAR)\n",
        "# img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Convert to RGB\n",
        "# coords= resize_boxes(torch.tensor(ret[30][\"boxes\"][0]),ret[30][\"image_size\"][:2],(640,640))\n",
        "# coords = [int(t) for t in list(coords.squeeze(0))]\n",
        "# cv2.rectangle(img, (int(coords[0]), int(coords[1])), (int(coords[2]), int(coords[3])),color=(0, 255, 0), thickness=3) # Draw Rectangle with the coordinates\n",
        "# #cv2.putText(img,pred_cls[i], boxes[i][0],  cv2.FONT_HERSHEY_SIMPLEX, text_size, (0,255,0),thickness=text_th) # Write the prediction class\n",
        "# plt.figure(figsize=(20,30)) # display the output image\n",
        "# plt.imshow(img)\n",
        "# plt.xticks([])\n",
        "# plt.yticks([])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nmfgPy2fNH08"
      },
      "source": [
        "### Create train and test buckets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mvM13gN9NH08",
        "colab": {}
      },
      "source": [
        "#Get number of boxes for each image\n",
        "def create_tensors_for_data_loader(data):\n",
        "    #lengths = [len(t[\"boxes\"]) for t in train_subset]\n",
        "    lengths = []\n",
        "    #Create packed_boxes for all images together\n",
        "    boxes = ()\n",
        "    width = 640\n",
        "    images = torch.empty(0,3,width,width)\n",
        "    transform = transforms.Compose([transforms.Resize((width,width)),\n",
        "                                    transforms.ToTensor()])\n",
        "    labels_tensor = torch.empty(0,NUM_CLASSES)\n",
        "    for t in data:\n",
        "        size = t[\"image_size\"]\n",
        "        if len(t[\"boxes\"]) == 0:\n",
        "            image_boxes = torch.tensor([[0,0,size[1],size[0]]])\n",
        "        else:\n",
        "            image_boxes = torch.tensor(t[\"boxes\"])    \n",
        "\n",
        "        #img_path = data_directory + \"hico_clean/images/subset/\" + t[\"image_path\"]\n",
        "        img_path = data_directory + \"hico_clean/images/subset/\" + t[\"image_path\"]\n",
        "        img = Image.open(img_path)\n",
        "        img = transform(img)\n",
        "        img = img.unsqueeze(0)\n",
        "        if img.shape[1] == 1:\n",
        "            img = img.repeat(1,3,1,1)\n",
        "        images = torch.cat((images,img), dim = 0)\n",
        "\n",
        "        label_tensor = torch.zeros(1,NUM_CLASSES)\n",
        "        labels = t[\"labels\"]\n",
        "        \n",
        "        #Create one_hot encoding of image labels\n",
        "        for label in labels:\n",
        "            label_tensor[0,int(label)] = 1.\n",
        "\n",
        "        labels_tensor = torch.cat((labels_tensor, label_tensor), dim = 0)\n",
        "        resized_boxes = resize_boxes(image_boxes, size[:2], (width,width))\n",
        "        boxes += torch.unbind(resized_boxes.unsqueeze(0))\n",
        "        lengths.append(len(image_boxes))\n",
        "\n",
        "    packed_boxes = pad_sequence(boxes, batch_first=True)\n",
        "    return images, packed_boxes, labels_tensor, lengths"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M6QgK9uANH0_",
        "colab": {}
      },
      "source": [
        "# data_directory = \"/content/images/\"\n",
        "# import pickle, gc\n",
        "# ts = time.time()\n",
        "# batch_size = 10\n",
        "# for i in range(11):\n",
        "#   train_images, train_boxes, train_labels, train_lengths = create_tensors_for_data_loader(train_annot[i*1000:(i+1)*1000])\n",
        "#   torch.save(train_images, data_directory + \"train_images_\"+str(i) +\".pt\")\n",
        "#   torch.save(train_boxes, data_directory + \"train_boxes_\"+str(i) +\".pt\")\n",
        "#   torch.save(train_labels, data_directory + \"train_labels_\"+str(i) +\".pt\")\n",
        "  \n",
        "#   with open(data_directory + \"train_lengths_\"+str(i) +\".txt\", \"wb\") as f:\n",
        "#     pickle.dump(train_lengths, f)\n",
        "  \n",
        "#   gc.collect()\n",
        "# print(\"Time taken\", time.time() - ts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltjrC5XdRl-6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_images, test_boxes, test_labels, test_lengths = create_tensors_for_data_loader(test_annot)\n",
        "# torch.save(train_images, data_directory + \"test_images.pt\")\n",
        "# torch.save(train_boxes, data_directory + \"test_boxes.pt\")\n",
        "# torch.save(train_labels, data_directory + \"test_labels.pt\")\n",
        "\n",
        "# with open(data_directory + \"test_lengths.txt\", \"wb\") as f:\n",
        "#   pickle.dump(train_lengths, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-lbmOYWOuwM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from shutil import copyfile\n",
        "# import os\n",
        "# files = os.listdir(\"/content/images/\")\n",
        "# for file in files:\n",
        "#   if \".\" in file:\n",
        "#     copyfile(\"/content/images/\"+file, \"/content/drive/My Drive/Research/Data/Tensors/\" + file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agXmzcQ6LR5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "test_images = torch.load(data_directory + \"test_images.pt\")\n",
        "test_boxes = torch.load(data_directory + \"test_boxes.pt\")\n",
        "test_labels = torch.load(data_directory + \"test_labels.pt\")\n",
        "with (open(data_directory + \"test_lengths.txt\", \"rb\")) as picklefile:\n",
        "  test_lengths = pickle.load(picklefile)\n",
        "test_bucket = BucketDataset(test_images, test_boxes, test_labels, test_lengths, batch_size = 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CF9ziWgONH1g",
        "outputId": "79b87cb3-98b9-426f-8a2e-76d5e2235a8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_net(model, test_bucket, gpu = gpu_flag)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch number  0\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8210586905479431\n",
            "Train average precision is  0.017475585505123525\n",
            "Test average precision 0.00440461355403573\n",
            "Epoch 0 Iteration  0 Partition 0 running_loss 0.8210586905479431\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8071987628936768\n",
            "Epoch 0 Iteration  1 Partition 0 running_loss 1.6282574534416199\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8207950592041016\n",
            "Epoch 0 Iteration  2 Partition 0 running_loss 2.4490525126457214\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8205874562263489\n",
            "Epoch 0 Iteration  3 Partition 0 running_loss 3.2696399688720703\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8221161961555481\n",
            "Epoch 0 Iteration  4 Partition 0 running_loss 4.091756165027618\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8076977729797363\n",
            "Epoch 0 Iteration  5 Partition 0 running_loss 4.899453938007355\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8210638165473938\n",
            "Epoch 0 Iteration  6 Partition 0 running_loss 5.7205177545547485\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.807044506072998\n",
            "Epoch 0 Iteration  7 Partition 0 running_loss 6.527562260627747\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.819880485534668\n",
            "Epoch 0 Iteration  8 Partition 0 running_loss 7.3474427461624146\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8071359992027283\n",
            "Epoch 0 Iteration  9 Partition 0 running_loss 8.154578745365143\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.7946487069129944\n",
            "Epoch 0 Iteration  10 Partition 0 running_loss 8.949227452278137\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8207018375396729\n",
            "Epoch 0 Iteration  11 Partition 0 running_loss 9.76992928981781\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8202329874038696\n",
            "Epoch 0 Iteration  12 Partition 0 running_loss 10.59016227722168\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8077771067619324\n",
            "Epoch 0 Iteration  13 Partition 0 running_loss 11.397939383983612\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8078482151031494\n",
            "Epoch 0 Iteration  14 Partition 0 running_loss 12.205787599086761\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8082616329193115\n",
            "Epoch 0 Iteration  15 Partition 0 running_loss 13.014049232006073\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.7950399518013\n",
            "Epoch 0 Iteration  16 Partition 0 running_loss 13.809089183807373\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8079479932785034\n",
            "Epoch 0 Iteration  17 Partition 0 running_loss 14.617037177085876\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8195989727973938\n",
            "Epoch 0 Iteration  18 Partition 0 running_loss 15.43663614988327\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8064239621162415\n",
            "Epoch 0 Iteration  19 Partition 0 running_loss 16.24306011199951\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8205782175064087\n",
            "Epoch 0 Iteration  20 Partition 0 running_loss 17.06363832950592\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8207219243049622\n",
            "Epoch 0 Iteration  21 Partition 0 running_loss 17.884360253810883\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8204821348190308\n",
            "Epoch 0 Iteration  22 Partition 0 running_loss 18.704842388629913\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8054395914077759\n",
            "Epoch 0 Iteration  23 Partition 0 running_loss 19.51028198003769\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8185648322105408\n",
            "Epoch 0 Iteration  24 Partition 0 running_loss 20.32884681224823\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8191967010498047\n",
            "Epoch 0 Iteration  25 Partition 0 running_loss 21.148043513298035\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8069538474082947\n",
            "Epoch 0 Iteration  26 Partition 0 running_loss 21.95499736070633\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8078612089157104\n",
            "Epoch 0 Iteration  27 Partition 0 running_loss 22.76285856962204\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.807651162147522\n",
            "Epoch 0 Iteration  28 Partition 0 running_loss 23.57050973176956\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.818938672542572\n",
            "Epoch 0 Iteration  29 Partition 0 running_loss 24.389448404312134\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8191288709640503\n",
            "Epoch 0 Iteration  30 Partition 0 running_loss 25.208577275276184\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8212347030639648\n",
            "Epoch 0 Iteration  31 Partition 0 running_loss 26.02981197834015\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8074991106987\n",
            "Epoch 0 Iteration  32 Partition 0 running_loss 26.83731108903885\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8182713985443115\n",
            "Epoch 0 Iteration  33 Partition 0 running_loss 27.65558248758316\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8199751973152161\n",
            "Epoch 0 Iteration  34 Partition 0 running_loss 28.475557684898376\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8189256191253662\n",
            "Epoch 0 Iteration  35 Partition 0 running_loss 29.294483304023743\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8191047310829163\n",
            "Epoch 0 Iteration  36 Partition 0 running_loss 30.11358803510666\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8066504597663879\n",
            "Epoch 0 Iteration  37 Partition 0 running_loss 30.920238494873047\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8197171092033386\n",
            "Epoch 0 Iteration  38 Partition 0 running_loss 31.739955604076385\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8202511072158813\n",
            "Epoch 0 Iteration  39 Partition 0 running_loss 32.56020671129227\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8071943521499634\n",
            "Epoch 0 Iteration  40 Partition 0 running_loss 33.36740106344223\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8190808892250061\n",
            "Epoch 0 Iteration  41 Partition 0 running_loss 34.186481952667236\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8198761940002441\n",
            "Epoch 0 Iteration  42 Partition 0 running_loss 35.00635814666748\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8187100887298584\n",
            "Epoch 0 Iteration  43 Partition 0 running_loss 35.82506823539734\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.820232093334198\n",
            "Epoch 0 Iteration  44 Partition 0 running_loss 36.64530032873154\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8066020011901855\n",
            "Epoch 0 Iteration  45 Partition 0 running_loss 37.45190232992172\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8071064949035645\n",
            "Epoch 0 Iteration  46 Partition 0 running_loss 38.25900882482529\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8194339275360107\n",
            "Epoch 0 Iteration  47 Partition 0 running_loss 39.0784427523613\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8192845582962036\n",
            "Epoch 0 Iteration  48 Partition 0 running_loss 39.8977273106575\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.819240927696228\n",
            "Epoch 0 Iteration  49 Partition 0 running_loss 40.71696823835373\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.818910539150238\n",
            "Epoch 0 Iteration  50 Partition 0 running_loss 41.53587877750397\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.7806493043899536\n",
            "Epoch 0 Iteration  51 Partition 0 running_loss 42.31652808189392\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8195234537124634\n",
            "Epoch 0 Iteration  52 Partition 0 running_loss 43.136051535606384\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8193102478981018\n",
            "Epoch 0 Iteration  53 Partition 0 running_loss 43.955361783504486\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8201359510421753\n",
            "Epoch 0 Iteration  54 Partition 0 running_loss 44.77549773454666\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8055718541145325\n",
            "Epoch 0 Iteration  55 Partition 0 running_loss 45.581069588661194\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10, 49]) torch.Size([1, 4])\n",
            "Batch size 10 Loss 0.8184688687324524\n",
            "Train average precision is  0.02243017450063224\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}