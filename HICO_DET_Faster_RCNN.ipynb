{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "HICO DET Faster RCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kiranramnath007/ColabExperiments/blob/master/HICO_DET_Faster_RCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lusDX3lCvyiu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_CLASSES = 48"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xCQOoKtZNHyW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0817e444-9289-4187-cadc-baef012898ef"
      },
      "source": [
        "import torch, torchvision\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torchvision import transforms\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from torch import optim\n",
        "from collections import OrderedDict\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import time\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn.metrics import average_precision_score\n",
        "# For training\n",
        "images = torch.rand(10, 3, 287, 640)\n",
        "\n",
        "#7 box per image\n",
        "boxes1 = torch.ones(5, 7, 4) #2 images, 7 bbox, 4 co-ords\n",
        "labels1 = torch.randint(0,2, (5,NUM_CLASSES)).float()\n",
        "\n",
        "#11 boxes per image\n",
        "boxes2 = torch.zeros(5,11,4)\n",
        "labels2 = torch.randint(0,2,(5,NUM_CLASSES)).float()\n",
        "\n",
        "boxes = torch.unbind(boxes1) + torch.unbind(boxes2)\n",
        "#boxes = torch.zeros(5,11,4)\n",
        "labels = torch.cat((labels1, labels2), dim = 0)\n",
        "lengths = [7,7,7,7,7,11,11,11,11,11,11]\n",
        "#images = list(image for image in images)\n",
        "targets = []\n",
        "for i in range(len(images)):\n",
        "    d = {}\n",
        "    d['boxes'] = boxes[i]\n",
        "    #d['labels'] = labels[i]\n",
        "    targets.append(d)\n",
        "#output = model(images, targets)\n",
        "\n",
        "#Transform\n",
        "transform = transforms.Compose([transforms.Resize(256),\n",
        "                                transforms.CenterCrop(224),\n",
        "                                transforms.ToTensor()])\n",
        "\n",
        "#Pack bounding box tensor into one \n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "packed_boxes = pad_sequence(boxes, batch_first=True)\n",
        "packed_boxes.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 11, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nebt32yPCTWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MzEfCAs6NHyc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f78207c0-430f-4ccd-af95-1c6746b60675"
      },
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/drive/My Drive/Research/Code/\")\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "from fast_rcnn import *"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BEdR2zBLWLTy",
        "colab": {}
      },
      "source": [
        "!cp /content/drive/My\\ Drive/Research/Data/HICO_DET/subset.zip /content/subset.zip\n",
        "# #!unzip /content/drive/My\\ Drive/Research/Data/HICO_DET/subset.zip -d /content/drive/My\\ Drive/Research/Data/images2/\n",
        "!unzip /content/subset.zip -d /content/images/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kT-ypOb_H-1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r /content/drive/My\\ Drive/Research/Data/Tensors/ /content/\n",
        "!mv /content/Tensors/ /content/Images/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NOsLg79LBxK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import summary\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UmyX3_joNHyf",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "gpu_flag = False\n",
        "if torch.cuda.is_available():\n",
        "    gpu_flag = True\n",
        "model = fastrcnn_resnet50_fpn(pretrained_backbone=True, num_classes = NUM_CLASSES, trainable=True,gpu = gpu_flag)\n",
        "# model_dict = torch.load(\"/content/drive/My Drive/Research/Data/action_detector_epoch_6.pth\")\n",
        "# model.load_state_dict(model_dict[\"state_dict\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-0mbvhPhNHyk",
        "outputId": "1bf01e49-10be-4696-c2c7-3e8ca86acdf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "time_start = time.time()\n",
        "model.train()\n",
        "pos_weight = 10*torch.ones(NUM_CLASSES)\n",
        "if gpu_flag:\n",
        "    images = images.cuda()\n",
        "    labels = labels.cuda()\n",
        "    pos_weight = pos_weight.cuda()\n",
        "    for t in targets:\n",
        "        t[\"boxes\"] = t[\"boxes\"].cuda()\n",
        "predictions2 = model(images, targets, labels, pos_weight = pos_weight, batch_size = 10, gpu = gpu_flag)\n",
        "print(time.time()-time_start)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.13045310974121094\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xWVdjxXoNHyu",
        "colab": {}
      },
      "source": [
        "# For inference\n",
        "model.eval()\n",
        "pos_weight = 10*torch.ones(NUM_CLASSES)\n",
        "predictions = model(images, targets, labels, pos_weight = pos_weight, batch_size = 10, gpu = gpu_flag)\n",
        "predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A_8-7ArTNHyy",
        "colab": {}
      },
      "source": [
        "# Set the maximum sequence length. \n",
        "\n",
        "class BucketDataset:\n",
        "\n",
        "    def __init__(self, inputs, targets, labels, lengths, batch_size):\n",
        "        self.inputs = inputs      # shape = (N, max_seq_len)\n",
        "        self.targets = targets    # shape = (N, ) or None (e.g., for autoencoder I can simply use inputs)\n",
        "        self.lengths = lengths    # shape = (N, )\n",
        "        self.labels = labels\n",
        "        self.lengths_tensor = torch.tensor(self.lengths)\n",
        "        self.batch_size = batch_size\n",
        "        self.current = -1\n",
        "        self._generate_batch_map()\n",
        "\n",
        "    def _generate_batch_map(self, equal_length=False):\n",
        "        batch_map = OrderedDict()\n",
        "        # Organize lengths, e.g., batch_map[10] = [30, 124, 203, ...] <= indices of sequences of length 10\n",
        "        for idx, length in enumerate(self.lengths):\n",
        "            if length not in batch_map:\n",
        "                batch_map[length] = [idx]\n",
        "            else:\n",
        "                batch_map[length].append(idx)\n",
        "        # Use batch_map to split indices into batches of equal size\n",
        "        # e.g., for batch_size=3, batch_list = [[23,45,47], [49,50,62], [63,65,66], ...]\n",
        "        self.batch_list = []\n",
        "        for length, indices in batch_map.items():\n",
        "            for group in [indices[i:(i+self.batch_size)] for i in range(0, len(indices), self.batch_size)]:\n",
        "                self.batch_list.append((length,group))\n",
        "        self.batch_list = sorted(self.batch_list)\n",
        "        self.batch_list = [b[1] for b in self.batch_list]\n",
        "\n",
        "    def batch_count(self):\n",
        "        return len(self.batch_list)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.lengths)\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        self.current = self.current + 1\n",
        "        if self.current > len(self.batch_list)-1:\n",
        "            self.current = -1\n",
        "            raise StopIteration\n",
        "        else:\n",
        "            t = set(self.batch_list[self.current])\n",
        "            indices = [True if index in t else False for index in range(len(self.inputs))]\n",
        "            l = self.lengths_tensor[indices]\n",
        "\n",
        "            return self.inputs[indices], \\\n",
        "                   [{\"boxes\":t} for t in self.targets[indices][:,:l[0],:]], \\\n",
        "                   self.labels[indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Cv_qOUU4NH0h",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "import json\n",
        "anno_directory = \"/content/drive/My Drive/Research/Data/\"\n",
        "data_directory = \"/content/Images/\"\n",
        "with open(anno_directory + 'HICO_DET/subset_anno_list_reindexed.json') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# data_directory = \"../../Data/HICO/data_symlinks/\"\n",
        "# with open(data_directory + 'hico_processed/subset_anno_list_with_bg_class.json') as f:\n",
        "#     data = json.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RgLL0-4xNH0a",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "00a6aac6-3930-49d7-9689-8bd3b724a528"
      },
      "source": [
        "global_iter = 0\n",
        "def step(bucket, test_bucket, optimizer, model, pos_weight, epoch, partition,scheduler, gpu = False):\n",
        "    running_loss = 0.0\n",
        "    num_buckets = len(bucket.batch_list)\n",
        "    checkpoint_every = max(num_buckets // 10, 1)\n",
        "    time_start = time.time()\n",
        "    for index, mb in enumerate(bucket):\n",
        "      global_iter += 1\n",
        "        time_start_getting_data = time.time()\n",
        "        inputs, targets, labels = mb\n",
        "        if gpu:\n",
        "            inputs = inputs.cuda()\n",
        "            for t in targets:\n",
        "                t[\"boxes\"] = t[\"boxes\"].cuda()\n",
        "            labels = labels.cuda()\n",
        "            pos_weight = pos_weight.cuda()\n",
        "        batch_size = len(targets)\n",
        "        print(inputs.shape, labels.shape, targets[0][\"boxes\"].shape)\n",
        "        # print(\"Time to get data from minibatch\", time.time() - time_start_getting_data)\n",
        "        \n",
        "        time_start_forward = time.time()\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        model.train()\n",
        "        # forward + backward + optimize\n",
        "        #print(\"Labels \",labels.shape,\" image \",inputs.shape, \" batch_size \", batch_size)\n",
        "        losses = model(inputs, targets, labels, batch_size, pos_weight, gpu)\n",
        "        loss = losses[\"loss_classifier\"]\n",
        "        \n",
        "        # print(\"Time taken for forward pass\", time.time() - time_start_forward)\n",
        "        \n",
        "        time_start_backward_prop = time.time()        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # print(\"time taken for backward propagation\", time.time() - time_start_backward_prop)\n",
        "        print(\"Batch size\", batch_size, \"Loss\", loss.item())\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        if index % checkpoint_every == 0:\n",
        "            checkpoint = {'model': model,\n",
        "                      'state_dict': model.state_dict(),\n",
        "                      'optimizer' : optimizer.state_dict()}\n",
        "\n",
        "            torch.save(checkpoint, 'action_detector_epoch_'+str(epoch)+'.pth')\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                y_pred_train = model(inputs, targets, labels, batch_size, pos_weight, gpu)\n",
        "                if gpu:\n",
        "                    y_pred_train = y_pred_train.cpu()\n",
        "                    labels = labels.cpu()\n",
        "                train_average_precision = average_precision_score(labels, y_pred_train, average=\"micro\")\n",
        "                with train_summary_writer.as_default():\n",
        "                  summary.scalar('loss', loss.item(), step=global_iter)\n",
        "\n",
        "                print(\"Train average precision is \", train_average_precision)\n",
        "                \n",
        "                test_average_precision = 0\n",
        "                if test_bucket is None:\n",
        "                    continue\n",
        "                for test_mb in test_bucket:\n",
        "                    inputs, targets, labels = test_mb\n",
        "                    batch_size = len(targets)\n",
        "                    if gpu:\n",
        "                        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "                        for t in targets:\n",
        "                            t[\"boxes\"] = t[\"boxes\"].cuda()\n",
        "                            \n",
        "                    y_pred, test_loss = model(inputs, targets, labels, batch_size, pos_weight, gpu)            \n",
        "                    if gpu:\n",
        "                        y_pred = y_pred.cpu()\n",
        "                        labels = labels.cpu()\n",
        "                    test_average_precision += average_precision_score(labels, y_pred, average=\"micro\")\n",
        "                  with test_summary_writer.as_default():\n",
        "                    summary.scalar('loss', test_loss, step = globaliter)\n",
        "                    summary.scalar('accuracy', accuracy, step = globaliter)\n",
        "                print(\"Test average precision\", test_average_precision / len(test_bucket))\n",
        "        scheduler.step()        \n",
        "        print(\"Epoch\",epoch,\"Iteration \",index,\"Partition\",partition,\"running_loss\",running_loss)\n",
        "    return running_loss    "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-44a5b2e01996>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    time_start_getting_data = time.time()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pbc_Z2_jNH0d",
        "colab": {}
      },
      "source": [
        "from shutil import copyfile\n",
        "def train_net(model, test_bucket = None, start_epoch = 0, epochs = 20, batch_size = 64, gpu = False):\n",
        "    \n",
        "    optimizer = optim.SGD(model.parameters(), lr=1e-2, weight_decay=1e-4, momentum=0.98)\n",
        "    #scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 18000, gamma=0.1)\n",
        "    scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=1e-3, max_lr=5e-2, step_size_up = 300)\n",
        "    # pos_weight = 10*torch.ones(NUM_CLASSES) #10 is the weight attached to misclassified positive sample\n",
        "    pos_weight = torch.ones(NUM_CLASSES) #10 is the weight attached to misclassified positive sample\n",
        "\n",
        "    for epoch in range(start_epoch, epochs):\n",
        "        print(\"Epoch number \",epoch)\n",
        "        for partition in range(11):\n",
        "            images = torch.load(data_directory + \"train_images_\" + str(partition) + \".pt\")\n",
        "            boxes = torch.load(data_directory + \"train_boxes_\" + str(partition) + \".pt\")\n",
        "            labels = torch.load(data_directory + \"train_labels_\" + str(partition) + \".pt\")\n",
        "            with (open(data_directory + \"train_lengths_\" + str(partition) + \".txt\", \"rb\")) as picklefile:\n",
        "              lengths = pickle.load(picklefile)\n",
        "            buckets = BucketDataset(images, boxes, labels, lengths, batch_size)\n",
        "            step(buckets, test_bucket, optimizer, model,pos_weight,epoch, partition,scheduler,gpu)\n",
        "        copyfile('action_detector_epoch_'+str(epoch)+'.pth', anno_directory + 'action_detector_epoch_'+str(epoch)+'.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWCBTi3WWg30",
        "colab_type": "code",
        "outputId": "72a21437-f73e-4e06-d0bc-d91316c65cea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11180"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oARaqC01NH0k"
      },
      "source": [
        "### Extract ground truth bounding boxes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Gbw3r4gfNH0n",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "#This gets one-image one-bbox data\n",
        "\n",
        "def one_box_one_image_data(data):\n",
        "    per_image_data = {}\n",
        "    c = 0\n",
        "\n",
        "    for image_data in data:\n",
        "        global_id = image_data['global_id']\n",
        "        for hoi in image_data['hois']:\n",
        "            bbox = hoi['human_bboxes']\n",
        "            label = hoi['id']\n",
        "            image_path = image_data['image_path_postfix']\n",
        "            image_size = image_data['image_size']\n",
        "            per_image_data[c] = {\"bbox\":bbox, \"label\":int(label), \"path\":image_path,'image_size':image_size}\n",
        "            c += 1\n",
        "\n",
        "    l = []\n",
        "    for key in per_image_data:\n",
        "        l.append(per_image_data[key][\"label\"])\n",
        "\n",
        "    lt = torch.tensor(l)\n",
        "    one_hot = torch.nn.functional.one_hot(lt)\n",
        "\n",
        "    for index,t in enumerate(one_hot):\n",
        "        per_image_data[index][\"label\"] = t\n",
        "    \n",
        "    return per_image_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sQ1uyFGcNH0q",
        "colab": {}
      },
      "source": [
        "#This gets one-image all-box data\n",
        "\n",
        "def one_image_all_box_data(data):\n",
        "    ret = []\n",
        "    \n",
        "    for image_data in data:\n",
        "        global_id = image_data[\"global_id\"]\n",
        "        bboxes = []\n",
        "        labels = []\n",
        "        image_path = image_data['image_path_postfix']\n",
        "        image_size = image_data[\"image_size\"]\n",
        "        \n",
        "        for hoi in image_data[\"hois\"]:\n",
        "            bboxes += hoi[\"human_bboxes\"]\n",
        "            labels += [float(hoi[\"id\"])]*len(hoi[\"human_bboxes\"])\n",
        "                    \n",
        "        ret.append({\"global_id\":global_id, \"boxes\":bboxes, \"labels\":labels,\n",
        "                            \"image_path\":image_path,\"image_size\":image_size})\n",
        "    return ret\n",
        "ret = one_image_all_box_data(data)            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEZLisd_WdZN",
        "colab_type": "code",
        "outputId": "242f7e7b-8dea-438f-c4b6-1f2145cce6ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(ret)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11180"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ipb7xdwlNH0t",
        "colab": {}
      },
      "source": [
        "train_annot = [d for d in ret if d[\"image_path\"].startswith(\"train\")]\n",
        "test_annot = [d for d in ret if d[\"image_path\"].startswith(\"test\")]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m3ckzEdqNH0x",
        "colab": {}
      },
      "source": [
        "def resize_boxes(boxes, original_size, new_size):\n",
        "    # type: (Tensor, List[int], List[int])\n",
        "    ratios = [float(s) / float(s_orig) for s, s_orig in zip(new_size, original_size)]\n",
        "    ratio_height, ratio_width = ratios\n",
        "    xmin, ymin, xmax, ymax = boxes.unbind(1)\n",
        "\n",
        "    xmin = xmin * ratio_width\n",
        "    xmax = xmax * ratio_width\n",
        "    ymin = ymin * ratio_height\n",
        "    ymax = ymax * ratio_height\n",
        "    return torch.stack((xmin, ymin, xmax, ymax), dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d14WYUE0NH00",
        "outputId": "d8545d14-37ff-4a81-ebce-9196ac46145e",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "img_path = \"../../Data/HICO/data_symlinks/hico_clean/images/\"+ret[6953][\"image_path\"]\n",
        "#img = Image.open(img_path) # Load the image\n",
        "img = cv2.imread(img_path) # Read image with cv2\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Convert to RGB\n",
        "coords= ret[6953][\"boxes\"]\n",
        "for c in coords:\n",
        "    cv2.rectangle(img, (int(c[0]), int(c[1])), (int(c[2]), int(c[3])),color=(0, 255, 0), thickness=1) # Draw Rectangle with the coordinates\n",
        "#cv2.putText(img,pred_cls[i], boxes[i][0],  cv2.FONT_HERSHEY_SIMPLEX, text_size, (0,255,0),thickness=text_th) # Write the prediction class\n",
        "plt.figure(figsize=(20,30)) # display the output image\n",
        "plt.imshow(img)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "\n",
        "\n",
        "plt.imshow(img)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-75ca34156650>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#img = Image.open(img_path) # Load the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Read image with cv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Convert to RGB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6953\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"boxes\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_r1ZAuDPNH04",
        "colab": {}
      },
      "source": [
        "# img = cv2.imread(img_path) # Read image with cv2\n",
        "# img = cv2.resize(img, (640, 640), interpolation = cv2.INTER_LINEAR)\n",
        "# img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Convert to RGB\n",
        "# coords= resize_boxes(torch.tensor(ret[30][\"boxes\"][0]),ret[30][\"image_size\"][:2],(640,640))\n",
        "# coords = [int(t) for t in list(coords.squeeze(0))]\n",
        "# cv2.rectangle(img, (int(coords[0]), int(coords[1])), (int(coords[2]), int(coords[3])),color=(0, 255, 0), thickness=3) # Draw Rectangle with the coordinates\n",
        "# #cv2.putText(img,pred_cls[i], boxes[i][0],  cv2.FONT_HERSHEY_SIMPLEX, text_size, (0,255,0),thickness=text_th) # Write the prediction class\n",
        "# plt.figure(figsize=(20,30)) # display the output image\n",
        "# plt.imshow(img)\n",
        "# plt.xticks([])\n",
        "# plt.yticks([])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nmfgPy2fNH08"
      },
      "source": [
        "### Create train and test buckets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mvM13gN9NH08",
        "colab": {}
      },
      "source": [
        "#Get number of boxes for each image\n",
        "def create_tensors_for_data_loader(data):\n",
        "    #lengths = [len(t[\"boxes\"]) for t in train_subset]\n",
        "    lengths = []\n",
        "    #Create packed_boxes for all images together\n",
        "    boxes = ()\n",
        "    width = 256\n",
        "    images = torch.empty(0,3,width,width)\n",
        "    transform = transforms.Compose([transforms.Resize((width,width)),\n",
        "                                    transforms.ToTensor()])\n",
        "    labels_tensor = torch.empty(0,NUM_CLASSES)\n",
        "    for t in data:\n",
        "        size = t[\"image_size\"]\n",
        "        if len(t[\"boxes\"]) == 0:\n",
        "            image_boxes = torch.tensor([[0,0,size[1],size[0]]])\n",
        "        else:\n",
        "            image_boxes = torch.tensor(t[\"boxes\"])    \n",
        "\n",
        "        #img_path = data_directory + \"hico_clean/images/subset/\" + t[\"image_path\"]\n",
        "        img_path = \"/content/images/subset/\" + t[\"image_path\"]\n",
        "        img = Image.open(img_path)\n",
        "        img = transform(img)\n",
        "        img = img.unsqueeze(0)\n",
        "        if img.shape[1] == 1:\n",
        "            img = img.repeat(1,3,1,1)\n",
        "        images = torch.cat((images,img), dim = 0)\n",
        "\n",
        "        label_tensor = torch.zeros(1,NUM_CLASSES)\n",
        "        labels = t[\"labels\"]\n",
        "        \n",
        "        #Create one_hot encoding of image labels\n",
        "        for label in labels:\n",
        "            label_tensor[0,int(label)] = 1.\n",
        "\n",
        "        labels_tensor = torch.cat((labels_tensor, label_tensor), dim = 0)\n",
        "        resized_boxes = resize_boxes(image_boxes, size[:2], (width,width))\n",
        "        boxes += torch.unbind(resized_boxes.unsqueeze(0))\n",
        "        lengths.append(len(image_boxes))\n",
        "\n",
        "    packed_boxes = pad_sequence(boxes, batch_first=True)\n",
        "    return images, packed_boxes, labels_tensor, lengths"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M6QgK9uANH0_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3a4c8eb1-7d94-4a8b-a086-8ac4141831cf"
      },
      "source": [
        "# data_directory = \"/content/images/\"\n",
        "# import pickle, gc\n",
        "# ts = time.time()\n",
        "# batch_size = 10\n",
        "# for i in range(9):  \n",
        "#   train_images, train_boxes, train_labels, train_lengths = create_tensors_for_data_loader(train_annot[i*1000:(i+1)*1000])\n",
        "#   gc.collect()\n",
        "#   torch.save(train_images, data_directory + \"train_images_\"+str(i) +\".pt\")\n",
        "#   torch.save(train_boxes, data_directory + \"train_boxes_\"+str(i) +\".pt\")\n",
        "#   torch.save(train_labels, data_directory + \"train_labels_\"+str(i) +\".pt\")\n",
        "  \n",
        "#   with open(data_directory + \"train_lengths_\"+str(i) +\".txt\", \"wb\") as f:\n",
        "#     pickle.dump(train_lengths, f)\n",
        "    \n",
        "# print(\"Time taken\", time.time() - ts)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time taken 960.1106276512146\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltjrC5XdRl-6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test_images, test_boxes, test_labels, test_lengths = create_tensors_for_data_loader(test_annot)\n",
        "# test_bucket = BucketDataset(test_images, test_boxes, test_labels, test_lengths, batch_size = 1000)\n",
        "# torch.save(test_images, data_directory + \"test_images.pt\")\n",
        "# torch.save(test_boxes, data_directory + \"test_boxes.pt\")\n",
        "# torch.save(test_labels, data_directory + \"test_labels.pt\")\n",
        "\n",
        "# with open(data_directory + \"test_lengths.txt\", \"wb\") as f:\n",
        "#   pickle.dump(test_lengths, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-lbmOYWOuwM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from shutil import copyfile, move\n",
        "# import os\n",
        "# files = os.listdir(\"/content/images/\")\n",
        "# for file in files:\n",
        "#   if \".\" in file:\n",
        "#     copyfile(\"/content/images/\"+file, \"/content/drive/My Drive/Research/Data/Tensors/\" + file)\n",
        "#     move(\"/content/images/\"+file, \"/content/Images/\" + file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agXmzcQ6LR5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "test_images = torch.load(data_directory + \"test_images.pt\")\n",
        "test_boxes = torch.load(data_directory + \"test_boxes.pt\")\n",
        "test_labels = torch.load(data_directory + \"test_labels.pt\")\n",
        "with (open(data_directory + \"test_lengths.txt\", \"rb\")) as picklefile:\n",
        "  test_lengths = pickle.load(picklefile)\n",
        "test_bucket = BucketDataset(test_images, test_boxes, test_labels, test_lengths, batch_size = 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwOYT0R3NAAQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "current_time = str(datetime.datetime.now().timestamp())\n",
        "train_log_dir = 'logs/tensorboard/train/' + current_time\n",
        "test_log_dir = 'logs/tensorboard/test/' + current_time\n",
        "train_summary_writer = summary.create_file_writer(train_log_dir)\n",
        "test_summary_writer = summary.create_file_writer(test_log_dir)\n",
        "%tensorboard --logdir logs/tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CF9ziWgONH1g",
        "colab": {}
      },
      "source": [
        "train_net(model, test_bucket, gpu = gpu_flag)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}